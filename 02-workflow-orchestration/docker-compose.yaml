# =============================================================================
# Docker Compose - Airflow + Postgres Infrastructure
# =============================================================================
# Architecture:
# - postgres: Database for both Airflow metadata and taxi data
# - airflow-init: One-time initialization (create DB tables + admin user)
# - airflow-webserver: UI at http://localhost:8080
# - airflow-scheduler: DAG execution engine
# =============================================================================


# Shared config for Airflow services
x-airflow-common:
  &airflow-common
  image: apache/airflow:2.10.0-python3.11
  environment:
    - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    - AIRFLOW__CORE__LOAD_EXAMPLES=${AIRFLOW__CORE__LOAD_EXAMPLES}
    - AIRFLOW__WEBSERVER__WEB_SERVER_PORT=${AIRFLOW__WEBSERVER__WEB_SERVER_PORT}
    - AIRFLOW__WEBSERVER__SECRET_KEY=temporary_key_change_in_production
    - POSTGRES_HOST=${POSTGRES_HOST}
    - POSTGRES_PORT=${POSTGRES_PORT}
    - POSTGRES_DB=${POSTGRES_DB}
    - POSTGRES_USER=${POSTGRES_USER}
    - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    # Admin user credentials for airflow-init
    - AIRFLOW_ADMIN_USERNAME=${AIRFLOW_ADMIN_USERNAME}
    - AIRFLOW_ADMIN_PASSWORD=${AIRFLOW_ADMIN_PASSWORD}
    - AIRFLOW_ADMIN_FIRSTNAME=${AIRFLOW_ADMIN_FIRSTNAME}
    - AIRFLOW_ADMIN_LASTNAME=${AIRFLOW_ADMIN_LASTNAME}
    - AIRFLOW_ADMIN_EMAIL=${AIRFLOW_ADMIN_EMAIL}
    # Pre-configure postgres_default connection
    - AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
  volumes:
    - ./dags:/opt/airflow/dags:ro
    - ./logs:/opt/airflow/logs
    - ./queries:/opt/airflow/queries:ro
  user: "50000:0"
  depends_on:
    postgres:
      condition: service_healthy

services:
  # Postgres Database
  postgres:
    image: postgres:16
    container_name: airflow-postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "${POSTGRES_EXTERNAL_PORT}:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
      - ./init-postgres.sh:/docker-entrypoint-initdb.d/init.sh
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Airflow Init (one-time setup)
  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username "$${AIRFLOW_ADMIN_USERNAME}" \
          --password "$${AIRFLOW_ADMIN_PASSWORD}" \
          --firstname "$${AIRFLOW_ADMIN_FIRSTNAME}" \
          --lastname "$${AIRFLOW_ADMIN_LASTNAME}" \
          --role Admin \
          --email "$${AIRFLOW_ADMIN_EMAIL}" || true
    restart: "no"

  # Airflow Webserver (UI)
  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: webserver
    ports:
      - "${AIRFLOW_WEBSERVER_PORT}:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  # Airflow Scheduler (DAG execution)
  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    depends_on:
      airflow-init:
        condition: service_completed_successfully

volumes:
  postgres-db-volume:
