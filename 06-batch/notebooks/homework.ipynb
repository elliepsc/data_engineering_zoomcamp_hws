{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f9a40d",
   "metadata": {},
   "source": [
    "# Module 6 Homework — Apache Spark\n",
    "Data Engineering Zoomcamp 2026\n",
    "\n",
    "Dataset: Yellow Taxi November 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffca63",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ce592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Absolute paths — data/ is mounted at /home/jovyan/work/data/\n",
    "DATA_DIR = '/home/jovyan/work/data'\n",
    "TRIPS_PATH = os.path.join(DATA_DIR, 'yellow_tripdata_2025-11.parquet')\n",
    "ZONES_PATH = os.path.join(DATA_DIR, 'taxi_zone_lookup.csv')\n",
    "OUTPUT_PATH = os.path.join(DATA_DIR, 'yellow_2025_11_repartitioned')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('homework6') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "print(f'Spark version: {spark.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd3322f",
   "metadata": {},
   "source": [
    "## Question 1 — Spark version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bf8c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73cfca9",
   "metadata": {},
   "source": [
    "## Question 2 — Average parquet file size\n",
    "Read November 2025 Yellow Taxi data, repartition to 4 and save as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80117ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4,181,444\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(TRIPS_PATH)\n",
    "print(f'Total rows: {df.count():,}')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d250d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(4).write.parquet(OUTPUT_PATH, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba33504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parquet files: 4\n",
      "File sizes (MB): [24.41, 24.4, 24.41, 24.41]\n",
      "Average size: 24.41 MB\n"
     ]
    }
   ],
   "source": [
    "parquet_files = [f for f in os.listdir(OUTPUT_PATH) if f.endswith('.parquet')]\n",
    "sizes_mb = [os.path.getsize(os.path.join(OUTPUT_PATH, f)) / (1024 * 1024) for f in parquet_files]\n",
    "\n",
    "print(f'Number of parquet files: {len(parquet_files)}')\n",
    "print(f'File sizes (MB): {[round(s, 2) for s in sizes_mb]}')\n",
    "print(f'Average size: {sum(sizes_mb)/len(sizes_mb):.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8fc07e",
   "metadata": {},
   "source": [
    "## Question 3 — Trips on November 15th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4da8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips on November 15th: 162,604\n"
     ]
    }
   ],
   "source": [
    "count_nov15 = df.filter(\n",
    "    F.to_date(F.col('tpep_pickup_datetime')) == '2025-11-15'\n",
    ").count()\n",
    "\n",
    "print(f'Trips on November 15th: {count_nov15:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a219d7b",
   "metadata": {},
   "source": [
    "## Question 4 — Longest trip in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "399ef77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest trip: 90.6 hours\n"
     ]
    }
   ],
   "source": [
    "df_duration = df.withColumn(\n",
    "    'duration_hours',\n",
    "    (F.unix_timestamp('tpep_dropoff_datetime') - F.unix_timestamp('tpep_pickup_datetime')) / 3600\n",
    ")\n",
    "\n",
    "max_duration = df_duration.agg(F.max('duration_hours')).collect()[0][0]\n",
    "print(f'Longest trip: {max_duration:.1f} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6f4c8",
   "metadata": {},
   "source": [
    "## Question 5 — Spark UI port\n",
    "\n",
    "The Spark UI runs on port **4040**.\n",
    "\n",
    "Access it at: http://localhost:4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5d914",
   "metadata": {},
   "source": [
    "## Question 6 — Least frequent pickup zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0927e317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones = spark.read.option('header', 'true').csv(ZONES_PATH)\n",
    "zones.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc7ac96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+-----+\n",
      "|Zone                                         |count|\n",
      "+---------------------------------------------+-----+\n",
      "|Governor's Island/Ellis Island/Liberty Island|1    |\n",
      "|Arden Heights                                |1    |\n",
      "|Eltingville/Annadale/Prince's Bay            |1    |\n",
      "|Port Richmond                                |3    |\n",
      "|Rossville/Woodrow                            |4    |\n",
      "|Rikers Island                                |4    |\n",
      "|Green-Wood Cemetery                          |4    |\n",
      "|Great Kills                                  |4    |\n",
      "|Jamaica Bay                                  |5    |\n",
      "|Westerleigh                                  |12   |\n",
      "+---------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pickup_counts = df.groupBy('PULocationID').count()\n",
    "\n",
    "result = pickup_counts \\\n",
    "    .join(zones, pickup_counts['PULocationID'] == zones['LocationID'], 'left') \\\n",
    "    .select('Zone', 'count') \\\n",
    "    .orderBy('count') \\\n",
    "    .limit(10)\n",
    "\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e84fa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
